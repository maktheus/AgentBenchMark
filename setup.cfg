# ðŸ“¦ Package Configuration

[metadata]
name = ai-benchmark-service
version = 1.2.0
description = Service for evaluating AI agents performance
author = AI Benchmark Team
author_email = team@benchmark.example.com
license = MIT
long_description = file: README.md
long_description_content_type = text/markdown
url = https://github.com/your-org/benchmark-service
project_urls =
    Bug Tracker = https://github.com/your-org/benchmark-service/issues
    Documentation = https://docs.benchmark.example.com
    Source Code = https://github.com/your-org/benchmark-service

[options]
packages = find:
python_requires = >=3.11
install_requires =
    fastapi>=0.104.1
    uvicorn>=0.23.2
    httpx>=0.25.0
    pydantic>=2.4.2
    celery>=5.3.4
    redis>=5.0.1
    sqlalchemy>=2.0.21
    alembic>=1.13.0
    python-dotenv>=1.0.0
    weasyprint>=58.0
    jinja2>=3.1.2
    tenacity>=8.2.3
    prometheus-client>=0.17.1
    opentelemetry-api>=1.21.0
    opentelemetry-sdk>=1.21.0
    psycopg2-binary>=2.9.9
    pandas>=2.3.4
    numpy>=1.24.3
    scikit-learn>=1.3.0

[options.extras_require]
testing =
    pytest>=7.4.2
    pytest-asyncio>=0.21.1
    pytest-cov>=4.1.0
dev =
    black>=23.7.0
    flake8>=6.0.0
    mypy>=1.5.1
    bandit>=1.7.5
    safety>=2.3.5

[options.packages.find]
where = .
include = benchmark_service*

[bdist_wheel]
universal = 1

[flake8]
max-line-length = 88
extend-ignore = E203, W503
exclude = 
    .git,
    __pycache__,
    venv,
    .venv,
    build,
    dist,
    *.egg-info

[mypy]
python_version = 3.11
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
disallow_incomplete_defs = True
check_untyped_defs = True
disallow_untyped_decorators = True